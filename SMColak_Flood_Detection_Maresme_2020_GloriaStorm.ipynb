{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c894c7a",
   "metadata": {},
   "source": [
    "PREPARING DATA:\n",
    "\n",
    "\n",
    "** A kml file has been prepared at the google maps for defining the boarders of the ROI (Region of Interest)\n",
    "\n",
    "<img src=\"./Screenshot_googlemaps_polygon.png\" alt=\"Polygon at Googlemaps\" style=\"height: 500px; width:1000px;\"/>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "** I uploaded the .kml file to the website \"https://dataspace.copernicus.eu/browser\" for donloading the Sentinel2 data\n",
    "\n",
    "<img src=\"./Screenshot_copernicusdatabase_polygon.png\" alt=\"Polygon at Copernicus DataBase\" style=\"height: 500px; width:1000px;\"/>\n",
    "\n",
    "\n",
    "** I used a custom script for selecting the data for downloading. Copernicus browser is already using an algorithm for the classification, I used their script and excluded the other classes apart from the water\n",
    "\n",
    "Custom script for classified water:\n",
    "\n",
    "\n",
    "*********************************************************\n",
    "//VERSION=3\n",
    "\n",
    " function RGBToColor (r, g, b,dataMask){\n",
    "    return [r/255, g/255, b/255,dataMask];\n",
    "}\n",
    "\n",
    "function setup() {\n",
    "   return {\n",
    "    input: [\"SCL\",\"dataMask\"],\n",
    "    output: { bands: 4 }\n",
    "  };\n",
    "}\n",
    "\n",
    "function evaluatePixel(samples) {\n",
    "    const SCL=samples.SCL;\n",
    "    switch (SCL) {\n",
    "       \n",
    "    // Water (dark and bright) - blue\n",
    "    case 6: return RGBToColor (0, 0, 255,samples.dataMask);\n",
    "\n",
    "    }\n",
    "}\n",
    "\n",
    "************************************************************\n",
    "\n",
    "Ps: I couldn't directly download the Sentinel 2 data through jupyter notebook, because the older data goes to archive. But I kept the script for the reference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb946ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Downloading data from Sentinel which are not archieved\n",
    "\n",
    "#user = username \n",
    "#password = pwd\n",
    "#api = SentinelAPI(user, password, 'https://scihub.copernicus.eu/dhus')\n",
    "\n",
    "#products = api.query(geom,\n",
    "#date = ('20200202', '20200522'),\n",
    "#                     platformname = 'Sentinel-2',\n",
    "#                     processinglevel = 'Level-2A',\n",
    "#                     cloudcoverpercentage = (0, 20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594abf70",
   "metadata": {},
   "source": [
    "I downloaded two types of data:\n",
    "\n",
    "** One for observing the **effect** of the Gloria storm. Due to the clouds, the best possible option was February 2, 2020. Note that for an analysis with a longer working day option, using some other cloudy data and cleaning the weather effects with tools (i.e. ACOLITE) would be possible. (A paper on ACOLITE cleaned analysis: Caballero, 2019)\n",
    "\n",
    "** One for the **reference** for detecting the effects. Normally a day before the storm could be used, I downloaded February 8, 2020 data and did the analysis. Even though cloudiness < 20% choosen, the area was exposing to the rain, so there were effects prior to Gloria storm (January 15-25). Therefore, I decided to choose May 22, 2020 as a clean data. The decision choosing a date after is only due to not accesing the visible data at copernicus database in 2019.\n",
    "\n",
    "Reference:\n",
    "'2020-05-22-00 00_2020-05-22-23 59_Sentinel-2_L2A_Custom_script.jpg' --> **Used**\n",
    "\n",
    "'2020-01-08-00 00_2020-01-08-23 59_Sentinel-2_L2A_Custom_script.jpg' --> Not used at the end\n",
    "\n",
    "<img src=\"./2020-05-22-00 00_2020-05-22-23 59_Sentinel-2_L2A_Custom_script.jpg\" alt=\"Reference Only Water\" style=\"height: 500px; width:1000px;\"/>\n",
    "\n",
    "\n",
    "Flood:\n",
    "\n",
    "'2020-02-02-00 00_2020-02-02-23 59_Sentinel-2_L2A_Custom_script.jpg' --> **Used**\n",
    "\n",
    "<img src=\"./2020-02-02-00 00_2020-02-02-23 59_Sentinel-2_L2A_Custom_script.jpg\" alt=\"Flood Only Water\" style=\"height: 500px; width:1000px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1601b772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3760bdea",
   "metadata": {},
   "source": [
    "I used PCA (Principle Component Analysis) Method and - K-MEANS Clustering Technique to detect the differences between two images.\n",
    "\n",
    "Technique was proposed by Celik,Turgay (2009)\n",
    "\n",
    "I adapted some codes from ChaymaBouzaidii at github https://github.com/ChaymaBouzaidii/Change-detection-in-multitemporal-satellite-images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff71e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA\n",
    "import skimage.morphology\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bfaf7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_vector_set(diff_image, new_size):\n",
    " \n",
    "    i = 0\n",
    "    j = 0\n",
    "    vector_set = np.zeros((int(new_size[0] * new_size[1] / 25),25))\n",
    "    while i < vector_set.shape[0]:\n",
    "        while j < new_size[1]:\n",
    "            k = 0\n",
    "            while k < new_size[0]:\n",
    "                block   = diff_image[j:j+5, k:k+5]\n",
    "                feature = block.ravel()\n",
    "                vector_set[i, :] = feature\n",
    "                k = k + 5\n",
    "            j = j + 5\n",
    "        i = i + 1\n",
    " \n",
    "    mean_vec   = np.mean(vector_set, axis = 0)\n",
    "    # Mean normalization\n",
    "    vector_set = vector_set - mean_vec   \n",
    "    return vector_set, mean_vec\n",
    "\n",
    "def find_FVS(EVS, diff_image, mean_vec, new):\n",
    " \n",
    "    i = 2\n",
    "    feature_vector_set = []\n",
    " \n",
    "    while i < new[1] - 2:\n",
    "        j = 2\n",
    "        while j < new[0] - 2:\n",
    "            block = diff_image[i-2:i+3, j-2:j+3]\n",
    "            feature = block.flatten()\n",
    "            feature_vector_set.append(feature)\n",
    "            j = j+1\n",
    "        i = i+1\n",
    " \n",
    "    FVS = np.dot(feature_vector_set, EVS)\n",
    "    FVS = FVS - mean_vec\n",
    "    return FVS\n",
    "\n",
    "def clustering(FVS, components, new):\n",
    "    kmeans = KMeans(components, verbose = 0)\n",
    "    kmeans.fit(FVS)\n",
    "    output = kmeans.predict(FVS)\n",
    "    count  = Counter(output)\n",
    " \n",
    "    least_index = min(count, key = count.get)\n",
    "    change_map  = np.reshape(output,(new[1] - 4, new[0] - 4))\n",
    "    return least_index, change_map\n",
    "    \n",
    "\n"
   ]
  },
   "source": [
    "# Read Images\n",
    "\n",
    "\n",
    "\n",
    "image1_path= '2020-02-02-00 00_2020-02-02-23 59_Sentinel-2_L1C_NDWI.jpg'   ## Flood data\n",
    "image2_path = '2020-05-22-00 00_2020-05-22-23 59_Sentinel-2_L1C_NDWI.jpg'  ##My reference data\n",
    "\n",
    "image1 = cv2.imread(image1_path)\n",
    "image2 = cv2.imread(image2_path)\n",
    "\n",
    "\n",
    "\n",
    "# Resize Images\n",
    "\n",
    "new_size = np.asarray(image1.shape) /5\n",
    "new_size = new_size.astype(int) *5\n",
    "image1 = cv2.resize(image1, (new_size[0],new_size[1])).astype(int)\n",
    "image2 = cv2.resize(image2, (new_size[0],new_size[1])).astype(int)\n",
    "\n",
    "\n",
    "# Difference Image\n",
    "\n",
    "diff_image = abs(image1 - image2)\n",
    "#cv2.imwrite('difference.jpg', diff_image)\n",
    "\n",
    "diff_image=diff_image[:,:,1]\n",
    "\n",
    "pca = PCA()\n",
    "vector_set, mean_vec=find_vector_set(diff_image, new_size)\n",
    "pca.fit(vector_set)\n",
    "EVS = pca.components_\n",
    "\n",
    "FVS = find_FVS(EVS, diff_image, mean_vec, new_size)\n",
    "components = 3\n",
    "\n",
    "least_index, change_map = clustering(FVS, components, new_size)\n",
    "\n",
    "\n",
    "change_map[change_map == least_index] = 255\n",
    "change_map[change_map != 255] = 0\n",
    "change_map = change_map.astype(np.uint8)\n",
    "\n",
    "\n",
    "#cv2.imwrite('ChangeMap.jpg', change_map)\n",
    "\n",
    "kernel = skimage.morphology.disk(6)\n",
    "CloseMap = cv2.morphologyEx(change_map, cv2.MORPH_CLOSE, kernel)\n",
    "cv2.imwrite('CloseMap.jpg', CloseMap)\n",
    "\n",
    "#OpenMap = cv2.morphologyEx(CloseMap, cv2.MORPH_OPEN, kernel)\n",
    "#cv2.imwrite('OpenMap.jpg', OpenMap)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a28f224",
   "metadata": {},
   "source": [
    "I found the following results with Comparing February 2, May 22 in 2020\n",
    "\n",
    "<img src=\"./water_02_05ChangeMap.jpg\" alt=\"Water effect February 2, 2020\" style=\"height: 700px; width:500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052a7701",
   "metadata": {},
   "source": [
    "When I used January 8th as a reference, I found the following results:\n",
    "\n",
    "<img src=\"./water_02_01ChangeMap.jpg\" alt=\"Water effect February 2, 2020\" style=\"height: 700px; width:500px;\"/>\n",
    "\n",
    "Note that this image includes more water area but that is due to rain received **before** the storm. By definition date of the storm, I decided not to include the effects before the storm. Therefore I didn't use this result\n",
    "\n",
    "The second effect I want to take attention is the following: There was a cloud density at the bottom left of January 8th data set, which caused a false increase in the amount of water classification at the lower left seaside.\n",
    "\n",
    "\n",
    "Here is the classification map for **January 8** downloaded from Copernicus DB\n",
    "\n",
    "<img src=\"./2020-01-08-00:00_2020-01-08-23:59_Sentinel-2_L2A_Scene_classification_map.jpg\" alt=\"Classification January 8, 2020\" style=\"height: 700px; width:700px;\"/>\n",
    "\n",
    "And here is the classification map for **February 2** downloaded from Copernicus DB\n",
    "\n",
    "<img src=\"./2020-02-02-00:00_2020-02-02-23:59_Sentinel-2_L2A_Scene_classification_map.jpg\" alt=\"Classification February 2, 2020\" style=\"height: 700px; width:700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c77277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
